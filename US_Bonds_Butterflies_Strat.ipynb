{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47371c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "import rpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fd87a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "antonPath = False\n",
    "alexPath = True \n",
    "if alexPath == True :\n",
    "    wd = \"C:\\\\Users\\\\alexa\\\\Desktop\\\\FixedIncomeStrat\"\n",
    "else:\n",
    "    wd = \"/Users/antonaleynikov/Desktop/Fixed Income Sentiment strat\"\n",
    "os.chdir(wd)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29984cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, folders, files in os.walk(wd):\n",
    "    print(\"folders:\", folders)\n",
    "    print(\"files:\", files)\n",
    "    print(\"path:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada79a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(wd, \"Data\")\n",
    "if alexPath == True :\n",
    "    datafiles_names = os.listdir(wd + \"\\\\Data\")\n",
    "else :\n",
    "    datafiles_names = os.listdir(wd + \"/Data\")\n",
    "    \n",
    "\n",
    "filenames = [filename.split(\".\") for filename in datafiles_names[2:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4442b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in filenames:\n",
    "    file_name = file[0]\n",
    "    file_format = file[1]\n",
    "    file_path = os.path.join(data_path , \".\".join(file))\n",
    "    df = pd.read_excel(file_path, index_col = \"Dates\")\n",
    "    if file_format == \"xlsx\":\n",
    "        df = pd.read_excel(file_path, index_col = \"Dates\")\n",
    "    globals()[file_name] = df \n",
    "locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121989c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yields.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7717c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "Exogen[\"SPX_EP_YIELD_SPREAD\"] = Exogen[\"SPX_PE_RATIO\"].apply(lambda x: 1 / x) - (Forwards[\"Average\"][:-1] / 100).values\n",
    "del Exogen[\"SPX_PE_RATIO\"]\n",
    "Exogen[\"FORWARDS\"] = Forwards[\"Average\"][:-1].values\n",
    "Exogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a6c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as lm \n",
    "\n",
    "\n",
    "def get_lam(yields, lam_seq):\n",
    "    \"get lambda given known yields and a searching grid\"\n",
    "    if 0 in lam_seq:\n",
    "        print(\"Remove zero from search grid\")\n",
    "    maturities = np.array([1/12, 1/4,1/2 ,1 , 2, 3, 5, 7, 10, 20, 30])\n",
    "    r2 = pd.DataFrame(0, index=np.arange(yields.shape[0]), columns=lam_seq)\n",
    "    for j in range(len(lam_seq)):\n",
    "        lam = lam_seq[j]\n",
    "        \n",
    "        # Initialise regressors based on lambda \n",
    "        regs = pd.DataFrame()\n",
    "        regs[\"level_reg\"] = [1 for t in maturities]\n",
    "        regs[\"slope_reg\"] = [(1 - np.exp(-lam * t))/(lam * t) for t in maturities]\n",
    "        regs[\"curv_reg\"] = [(1 - np.exp(-lam * t))/(lam * t) - np.exp(-lam*t) for t in maturities]\n",
    "        \n",
    "        # Fit yields to regressors\n",
    "        factors = pd.DataFrame({\"level\": \"\", \"slope\": \"\", \"curvature\": \"\"},index = yields.index)\n",
    "        for i in range(yields.shape[0]):\n",
    "            X = regs.values\n",
    "            y = yields.iloc[i].values\n",
    "            reg = lm().fit(X, y)\n",
    "            level, slope ,curv = reg.intercept_, reg.coef_[1], reg.coef_[2]\n",
    "            rsq = reg.score(X,y)\n",
    "            factors.iloc[i] = [level, slope, curv]\n",
    "            r2.iloc[i,j] = rsq\n",
    "    lam_max = r2.mean().idxmax()\n",
    "    return lam_max\n",
    "        \n",
    "# get_lam(yields, np.linspace(0.1,1,10))\n",
    "\n",
    "def fit_factors(yields, lam):\n",
    "    factors = pd.DataFrame({\"level\": \"\", \"slope\": \"\", \"curvature\": \"\"},index = yields.index)\n",
    "    \n",
    "    # Initialise regressors based on lambda\n",
    "    maturities = np.array([1/12, 1/4,1/2 ,1 , 2, 3, 5, 7, 10, 20, 30])\n",
    "    regs = pd.DataFrame()\n",
    "    regs[\"level_reg\"] = [1 for t in maturities]\n",
    "    regs[\"slope_reg\"] = [(1 - np.exp(-lam * t))/(lam * t) for t in maturities]\n",
    "    regs[\"curv_reg\"] = [(1 - np.exp(-lam * t))/(lam * t) - np.exp(-lam*t) for t in maturities]\n",
    "    \n",
    "    for row in range(factors.shape[0]):\n",
    "        reg = lm().fit(regs.values, yields.iloc[row].values)\n",
    "        level = reg.intercept_\n",
    "        slope , curv = reg.coef_[1], reg.coef_[2]\n",
    "        factors.iloc[row] = [level, slope, curv]\n",
    "    return factors\n",
    "\n",
    "# lam = get_lam(yields, np.linspace(0.1,1,10))\n",
    "# factors = fit_factors(yields, lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7129e5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = get_lam(Yields, np.linspace(0.1,1,10))\n",
    "factors = fit_factors(Yields, lam)\n",
    "dfact = factors.diff()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a293c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects.vectors import FloatVector\n",
    "from rpy2.robjects import pandas2ri\n",
    "utils = importr(\"utils\")\n",
    "# utils.chooseCRANmirror(ind=1)\n",
    "# utils.install_packages('rugarch')\n",
    "# utils.install_packages('forecast')\n",
    "forecast = importr('forecast')\n",
    "rugarch = importr('rugarch')\n",
    "base = importr('base')\n",
    "\n",
    "# X is a Panda Series that contains the returns I want to fit the model\n",
    "returns = FloatVector(dfact[\"slope\"].values)   \n",
    "with (ro.default_converter + pandas2ri.converter).context():\n",
    "     exo = ro.conversion.get_conversion().py2rpy(Exogen)\n",
    "\n",
    "ro.r(\"\"\"  \n",
    "     f <- function (series, exogen) {\n",
    "     spec = ugarchspec(\n",
    "     mean.model=list(armaOrder=auto.arima(series)$arma[1:2], external.regressors = exogen),\n",
    "     variance.model=list(garchOrder=c(1,1)),\n",
    "     distribution.model=\"sged\"\n",
    "     ) \n",
    "\n",
    "     fit = tryCatch(\n",
    "     ugarchfit(\n",
    "     spec, series, solver = 'hybrid'\n",
    "     ), error=function(e) e, warning=function(w) w\n",
    "     )  \n",
    "     fore = ugarchforecast(fit, n.ahead=1)\n",
    "     ind = fore@forecast$seriesFor\n",
    "     ind\n",
    "     }\"\"\")\n",
    "\n",
    "fcast_armax = ro.globalenv['f']\n",
    "fore = fcast_armax(returns, base.as_matrix(exo))[0]\n",
    "\n",
    "fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9aa06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_armax(yields, exogen_nopca, exogen_pca, factor_name, w_len):\n",
    "    fcast = {}\n",
    "    s_len = yields.shape[0] - 1\n",
    "    for t in range(s_len - w_len):\n",
    "        end = t + w_len\n",
    "        lam = get_lam(yields[t:end], np.linspace(0.1,0.7,10))\n",
    "        dfactors = fit_factors(yields[t:end], lam).diff()[1:]\n",
    "        \n",
    "        if exogen_pca.any()[0] == True:\n",
    "            # Standardise\n",
    "            scaled = StandardScaler().fit_transform(exogen_pca[t:end])\n",
    "\n",
    "            # PCA transform\n",
    "            pca = PCA(n_components=1)  # You can choose the number of components you want to keep\n",
    "            p_comp = pd.Series(pca.fit_transform(scaled)[:,0], index = exogen_nopca[t:end].index)\n",
    "\n",
    "            dt = pd.concat([exogen_nopca[t:end], p_comp], axis = 1)\n",
    "        else:\n",
    "            dt = exogen_nopca[t:end]\n",
    "\n",
    "        \n",
    "        series = FloatVector(dfactors[factor_name].values)   \n",
    "        with (ro.default_converter + pandas2ri.converter).context():\n",
    "                exo = ro.conversion.get_conversion().py2rpy(dt)\n",
    "\n",
    "        fore = fcast_armax(series, base.as_matrix(exo))[0]\n",
    "        fcast[yields.index.values[end]] = fore\n",
    "\n",
    "    return pd.Series(fcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef58132",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_len = 150\n",
    "num_rows = 3\n",
    "num_columns = 4\n",
    "\n",
    "# Create a DataFrame filled with zeros\n",
    "zeros_df = pd.DataFrame(0, index=range(num_rows), columns=range(num_columns))\n",
    "zeros_df.any()[0]\n",
    "slope_fore = roll_armax(Yields, Exogen, zeros_df, \"slope\", w_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d184237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "dfact[\"slope\"][w_len:].plot(color = 'blue')\n",
    "slope_fore.plot(color = 'red')\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48fd7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def predict_yield_at_maturity(level, slope, curvature, maturity, lambda_):\n",
    "    level_part = level\n",
    "    slope_part = slope * ((1 - exp(-maturity * lambda_)) / (maturity * lambda_))\n",
    "    curvature_part = curvature * (((1 - exp(-maturity * lambda_)) / (maturity * lambda_)) - exp(-maturity * lambda_))\n",
    "    yield_prediction = level_part + slope_part + curvature_part\n",
    "    return yield_prediction\n",
    "\n",
    "\n",
    "def dollar_level_duration_zerocoupon(face_value, maturity, yield_prediction):\n",
    "    '''\n",
    "  Contains information on how a change in the level factor influences the price change of a bond (with a certain maturity)\n",
    "\n",
    "  Compute the D0 from page 197 in the book\n",
    "  face_value = F(maturity) -> 0 for all intermediate timesteps until maturity (zero-coupon)\n",
    "  '''\n",
    "    return (-maturity * face_value * exp(-maturity * yield_prediction))\n",
    "\n",
    "\n",
    "def dollar_slope_duration_zerocoupon(face_value, maturity, yield_prediction, lambda_):\n",
    "    '''\n",
    "  Contains information on how a change in the slope factor influences the price change of a bond (with a certain maturity)\n",
    "\n",
    "\n",
    "  Compute the D1 from page 197 in the book\n",
    "  face_value = F(maturity) -> 0 for all intermediate timesteps until maturity (zero-coupon)\n",
    "  '''\n",
    "    slope_fac = (1 - exp(-maturity * lambda_)) / (maturity * lambda_)\n",
    "    return slope_fac * (-maturity * face_value * exp(-maturity * yield_prediction))\n",
    "\n",
    "\n",
    "def dollar_curvature_duration_zerocoupon(face_value, maturity, yield_prediction, lambda_):\n",
    "    '''\n",
    "  Contains information on how a change in the curvature factor influences the price change of a bond (with a certain maturity)\n",
    "\n",
    "  Compute the D2 from page 197 in the book\n",
    "  face_value = F(maturity) -> 0 for all intermediate timesteps until maturity (zero-coupon)\n",
    "  '''\n",
    "    curvature_fac = ((1 - exp(-maturity * lambda_)) / (maturity * lambda_)) - exp(-maturity * lambda_)\n",
    "    return curvature_fac * (-maturity * face_value * exp(-maturity * yield_prediction))\n",
    "\n",
    "\n",
    "def predict_price_change_due_to_factor(factor_prev, factor_next, factor_dollar_duration):\n",
    "    '''\n",
    "  Computes the predicted change in price due to a change in factor\n",
    "\n",
    "  factor_dollar_duration: for chosen maturity this gives the ratio at which a change in the factor influences the price\n",
    "  factor_prev: the last obeserved factor (at time t)\n",
    "  factor_next: the predicted factor (at time t+1)\n",
    "  '''\n",
    "    return (factor_next - factor_prev) * factor_dollar_duration\n",
    "\n",
    "\n",
    "def compute_hedge_terms(maturities_list, face_value, level_prev, slope_prev, curvature_prev, lambda_):\n",
    "    # def compute_hedge_terms(maturities_list, face_value, level_prev, level_pred, slope_prev, slope_pred, curvature_prev, curvature_pred):\n",
    "    '''\n",
    "  maturities_list: a list of the maturities of the bonds we want to trade\n",
    "  '''\n",
    "    D0_list = []\n",
    "    D1_list = []\n",
    "    D2_list = []\n",
    "\n",
    "    # computing the dollar durations for the different factors\n",
    "    for maturity in maturities_list:\n",
    "        yield_pred = predict_yield_at_maturity(level=level_prev, slope=slope_prev, curvature=curvature_prev,\n",
    "                                               maturity=maturity, lambda_=lambda_)\n",
    "        # for a maturity we look at how sensitive the according bond price is to changes in the factor that describes the yield curve\n",
    "        D0_list.append(\n",
    "            dollar_level_duration_zerocoupon(face_value=face_value[0], maturity=maturity, yield_prediction=yield_pred))\n",
    "        D1_list.append(\n",
    "            dollar_slope_duration_zerocoupon(face_value=face_value[1], maturity=maturity, yield_prediction=yield_pred,\n",
    "                                             lambda_=lambda_))\n",
    "        D2_list.append(dollar_curvature_duration_zerocoupon(face_value=face_value[2], maturity=maturity,\n",
    "                                                            yield_prediction=yield_pred, lambda_=lambda_))\n",
    "\n",
    "    # predicting price changes for different factors (D0=level, D1=slope, D2=curvature) across multiple maturities (thats why using list)\n",
    "    # D0_price_changes_list = [(level_pred - level_prev) * D0_at_mat for D0_at_mat in D0_list]\n",
    "    # D1_price_changes_list = [(slope_pred - slope_prev) * D1_at_mat for D1_at_mat in D1_list]\n",
    "    # D2_price_changes_list = [(curvature_pred - curvature_prev) * D2_at_mat for D2_at_mat in D2_list]\n",
    "\n",
    "    return D0_list, D1_list, D2_list\n",
    "\n",
    "\n",
    "def compute_hedge_weights_basic(D0_list, D1_list, D2_list, wanted_exposure=\"curvature\"):\n",
    "    '''\n",
    "  Uses the basic hedging that is used in the original paper.\n",
    "  Idea: choose the weights in such a way that the exposure to two of the thre factors cancel out across the multiple maturities\n",
    "\n",
    "  Carefull: If a factor is contained in the hedging equations\n",
    "  '''\n",
    "\n",
    "    to_hedge = []\n",
    "\n",
    "    if wanted_exposure == \"level\":\n",
    "        to_hedge = [D0_list, D2_list]\n",
    "    elif wanted_exposure == \"slope\":\n",
    "        to_hedge = [D1_list, D2_list]\n",
    "    elif wanted_exposure == \"curvature\":\n",
    "        to_hedge = [D0_list, D1_list]\n",
    "    else:\n",
    "        print(\"ERROR: Chose a wanted_exposure that does not exist!\")\n",
    "\n",
    "    # Construct the linear system that includes the hedging equations: A*x=b\n",
    "    A = np.ones((3, 3))\n",
    "    for i in range(len(to_hedge)):\n",
    "        A[i, :] = to_hedge[i]\n",
    "    b = np.array([0, 0, 1])\n",
    "    b.shape = (3, 1)  # make it a column vector\n",
    "\n",
    "    # solve the linear system: x = A(-1) * b\n",
    "    A_inv = np.linalg.inv(A)\n",
    "    exposure_weights = A_inv.dot(b)\n",
    "\n",
    "    return exposure_weights\n",
    "\n",
    "\n",
    "def compute_hedge_weights_basic_df(actual_factors_df, predicted_factor_changes_df, maturities_list, face_value,\n",
    "                                   lambdas):\n",
    "    '''\n",
    "  # New\n",
    "  Takes a dataframe.\n",
    "  '''\n",
    "    predicted_weights = pd.DataFrame()\n",
    "    D0_list_full = []\n",
    "    D1_list_full = []\n",
    "    D2_list_full = []\n",
    "\n",
    "    for i in range(0, len(predicted_factor_changes_df)):\n",
    "        # load realized factors from last month (i)\n",
    "        # level_prev = actual_factors_df.loc[i, 'level']\n",
    "        # slope_prev = actual_factors_df.loc[i, 'slope']\n",
    "        # curvature_prev = actual_factors_df.loc[i, 'curvature']\n",
    "\n",
    "        # compute predicted factors for this month (i) based one (VAR) predicted changes in the factor\n",
    "        # level_pred = level_prev + predicted_factor_changes_df.loc[i, 'level']\n",
    "        # slope_pred = slope_prev + predicted_factor_changes_df.loc[i, 'slope']\n",
    "        # curvature_pred = curvature_prev + predicted_factor_changes_df.loc[i, 'curvature']\n",
    "\n",
    "        # getting the realized factors of last month\n",
    "        level_realized = actual_factors_df.loc[i, 'level']\n",
    "        slope_realized = actual_factors_df.loc[i, 'slope']\n",
    "        curvature_realized = actual_factors_df.loc[i, 'curvature']\n",
    "        lambda_realized = lambdas.loc[len(predicted_factor_changes_df) + 1 + i][1]\n",
    "\n",
    "        # computing the sensitivities of the yield curve (at different maturities) to factor changes\n",
    "        D0_list, D1_list, D2_list = compute_hedge_terms(maturities_list, face_value, level_realized, slope_realized,\n",
    "                                                        curvature_realized, lambda_realized)\n",
    "        D0_list_full.append(D0_list)\n",
    "        D1_list_full.append(D1_list)\n",
    "        D2_list_full.append(D2_list)\n",
    "\n",
    "        # choosing exposure weights s.t. the sensitivity to 2 of the 3 factors are cancelled out and only exposure to one factor is left\n",
    "        predicted_weights = predicted_weights._append(pd.Series(\n",
    "        compute_hedge_weights_basic(D0_list, D1_list, D2_list, wanted_exposure).reshape(1, 3).tolist()[0]),\n",
    "            ignore_index=True)\n",
    "\n",
    "    return predicted_weights, D0_list_full, D1_list_full, D2_list_full"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
